{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e8951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393 431\n",
      "343 479\n",
      "343 479\n",
      "343 479\n",
      "343 479\n",
      "343 479\n",
      "343 479\n",
      "393 431\n",
      "393 431\n",
      "343 479\n",
      "343 479\n",
      "343 479\n",
      "344 479\n",
      "344 479\n",
      "344 479\n",
      "344 479\n",
      "394 432\n",
      "394 432\n",
      "344 479\n",
      "394 432\n",
      "344 479\n",
      "394 432\n",
      "394 432\n",
      "344 479\n",
      "393 432\n",
      "393 432\n",
      "343 479\n",
      "343 479\n",
      "343 479\n",
      "343 479\n",
      "343 479\n",
      "343 479\n",
      "343 479\n",
      "343 479\n",
      "343 479\n",
      "343 479\n",
      "343 479\n",
      "392 432\n",
      "392 432\n",
      "342 479\n",
      "392 431\n",
      "392 432\n",
      "392 431\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 432\n",
      "392 431\n",
      "342 479\n",
      "391 431\n",
      "341 479\n",
      "341 479\n",
      "340 479\n",
      "340 479\n",
      "339 479\n",
      "339 479\n",
      "338 479\n",
      "337 479\n",
      "337 479\n",
      "338 479\n",
      "337 479\n",
      "338 479\n",
      "339 479\n",
      "339 479\n",
      "340 479\n",
      "341 479\n",
      "343 479\n",
      "344 479\n",
      "345 479\n",
      "347 479\n",
      "349 479\n",
      "351 479\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Codigo de exemplo para extrair uma pessoa do fundo usando contornos e morfologia\n",
    "\n",
    "# Open webcam\n",
    "vidBuffer = cv2.VideoCapture(0)\n",
    "framerate = 60\n",
    "delayFrame = int(1.0 / framerate * 1000)\n",
    "\n",
    "while True:\n",
    "    flag, img = vidBuffer.read()\n",
    "    if not flag:\n",
    "        break\n",
    "\n",
    "    img = cv2.flip(img, 1) # Espelhar imagem\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use Otsu threshold for automatic separation\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Morphological operations to clean noise & fill holes\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Build mask\n",
    "    mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 5000:  # ignore tiny blobs\n",
    "            cv2.drawContours(mask, [cnt], -1, 255, thickness=-1)\n",
    "\n",
    "    mask = cv2.bitwise_not(mask) # Invert mask\n",
    "    \n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # Calcular contornos na mascara\n",
    "\n",
    "    \n",
    "    \n",
    "    # Centroide\n",
    "    cnt = max(contours, key=cv2.contourArea) # Maior contorno vai ser a pessoa\n",
    "    M = cv2.moments(cnt) # Obter moments\n",
    "    # Calcular centroide Cx = M10/M00, Cy = M01/M00\n",
    "    cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "    cv2.circle(img, (cx, cy), 5, (0, 0, 255), -1) # Desenhar centroide\n",
    "\n",
    "    pts = cnt.reshape(-1, 2) # Contorno passa a lista de pontos (x, y)\n",
    "\n",
    "    # Encontrar ponto mais distante do centroide (mão)\n",
    "    dx = pts[:, 0] - cx # Lista das distancias de x ao centroide\n",
    "    dy = pts[:, 1] - cy # Lista das distancias de y ao centroide\n",
    "    dists = np.hypot(dx, dy) # Lista das distancias euclidianas ao centroide\n",
    "\n",
    "    max_idx = np.argmax(dists) # Indice do ponto mais distante\n",
    "    hand_x, hand_y = pts[max_idx] # Coordenadas do ponto mais distante (mão)\n",
    "    hand_dist = dists[max_idx] # Distancia até ao ponto mais distante (mão)\n",
    "    \n",
    "    x, y, w, h = cv2.boundingRect(cnt) # Obter bounding box do corpo\n",
    "\n",
    "    # Condições para considerar \"braço esticado\"\n",
    "    if hand_dist > 0.3 * w: # Se a distância da mão ao centroide for > 30% da largura do corpo\n",
    "        # dy[max_idx], dx[max_idx] é o vetor centroide -> mão\n",
    "        angle_deg = np.degrees(np.arctan2(dy[max_idx], dx[max_idx])) # Obter o angulo em graus\n",
    "        # Em OpenCV, 0º é à direita, 90º é para baixo...\n",
    "        \n",
    "        # Para o brazo estar horizontal, o ângulo deve ser próximo de 0º ou 180º\n",
    "        is_horizontal = (abs(angle_deg) < 30) or (abs(abs(angle_deg) - 180) < 30)\n",
    "\n",
    "        if is_horizontal:\n",
    "            # Vetores da mão ao centroide normalizados\n",
    "            ux = dx[max_idx] / hand_dist\n",
    "            uy = dy[max_idx] / hand_dist\n",
    "\n",
    "            # Ponto \"ideal\" no meio do braço\n",
    "            # Ponto da centroide + vetor mão * 0.5 * distância mão-centroide\n",
    "            target_x = cx + ux * hand_dist * 0.5\n",
    "            target_y = cy + uy * hand_dist * 0.5\n",
    "\n",
    "            # Vetores de deslocamento até ao ponto ideal\n",
    "            diff_tx = pts[:, 0] - target_x\n",
    "            diff_ty = pts[:, 1] - target_y\n",
    "\n",
    "            dist_to_target = np.hypot(diff_tx, diff_ty) # Lista das distancias euclidianas ao ponto ideal\n",
    "            mid_idx = np.argmin(dist_to_target) # Obtem o ponto do contorno mais proximo ao ponto ideal\n",
    "            arm_cx, arm_cy = pts[mid_idx] # Coordenadas desse ponto\n",
    "            \n",
    "            xs = pts[:, 0] # Todos os valores X do contorno\n",
    "            diff_x = xs - arm_cx # Subtrair o X do braço de cada ponto do contorno\n",
    "            abs_diff_x = np.abs(diff_x) # Tirar o valor absoluto das diferenças\n",
    "            mask = abs_diff_x <= 5 # Mascara True para pontos na mesma coluna +-5px\n",
    "            mesma_coluna = np.where(mask)[0] # Obter os indices dos pontos onde a condição é verdadeira\n",
    "\n",
    "            if len(mesma_coluna) > 0: # Se houver\n",
    "                sub_pts = pts[mesma_coluna] # Pontos que estão na coluna do braço\n",
    "                top_idx_local = np.argmin(sub_pts[:, 1]) # Obtem o menor Y da lista de pontos\n",
    "                arm_cx, arm_cy = sub_pts[top_idx_local] # Coordenadas finais\n",
    "\n",
    "            arm_cx, arm_cy = int(arm_cx), int(arm_cy)\n",
    "            cv2.circle(img, (arm_cx, arm_cy), 7, (255, 0, 0), -1)\n",
    "            cv2.putText(img, \"Braco esticado\",\n",
    "                        (arm_cx + 10, arm_cy - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                        (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.drawContours(img, [cnt], -1, (0, 255, 0), 2)\n",
    "    cv2.circle(img, (int(hand_x), int(hand_y)), 5, (0, 255, 255), -1) # Desenhar ponto da mão\n",
    "    print(hand_x, hand_y)\n",
    "    #fg = cv2.bitwise_and(img, img, mask=mask) # Extract person\n",
    "    cv2.imshow(\"Person\", img)\n",
    "\n",
    "    key = cv2.waitKey(delayFrame)\n",
    "    if key == 27:  # ESC to exit\n",
    "        break\n",
    "\n",
    "vidBuffer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fde8e0d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     52\u001b[39m ini = \u001b[32m0\u001b[39m \u001b[38;5;66;03m# Frame inicial\u001b[39;00m\n\u001b[32m     53\u001b[39m fin = \u001b[32m10\u001b[39m \u001b[38;5;66;03m# Frame final\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m video1 = \u001b[43mAugmentedReality\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo0\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mini\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfin\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mAugmentedReality\u001b[39m\u001b[34m(video0, ini, fin)\u001b[39m\n\u001b[32m     11\u001b[39m videoWriter = cv2.VideoWriter(cut_name, -\u001b[32m1\u001b[39m, original.get(cv2.CAP_PROP_FPS), (width, height), \u001b[32m0\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Cortar o video entre os frames ini e fin\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCAP_PROP_FRAME_COUNT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     15\u001b[39m     ret, frame = original.read()\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n",
      "\u001b[31mTypeError\u001b[39m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "def AugmentedReality(video0, ini, fin): \n",
    "    # Abre o vídeo original\n",
    "    original = cv2.VideoCapture(video0)\n",
    "    \n",
    "    # Prepara o vídeo cortado\n",
    "    cut_name = \"cut_video.avi\"\n",
    "    height = int(original.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(original.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    \n",
    "    # Define o codec e cria o VideoWriter para o vídeo cortado\n",
    "    videoWriter = cv2.VideoWriter(cut_name, -1, original.get(cv2.CAP_PROP_FPS), (width, height), 0)\n",
    "    \n",
    "    # Cortar o video entre os frames ini e fin\n",
    "    for i in range(original.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
    "        ret, frame = original.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i >= ini and i <= fin:\n",
    "            videoWriter.write(frame)\n",
    "    \"\"\"\n",
    "    Common Issues:\n",
    "    Codec not supported: If the specified codec is not supported by your system, you may see an error message. \n",
    "    In this case, you can try using a different codec or adjusting the fourcc parameter.\n",
    "    Insufficient memory: If the video is too large, you may run out of memory. To mitigate this issue, you can try \n",
    "    reducing the frame rate or using a more efficient codec.\n",
    "    Incorrect frame rate: If the frame rate is incorrect, you may see a jerky or choppy video. To fix this issue, \n",
    "    you can adjust the fps parameter or use a different codec.\n",
    "    \"\"\"\n",
    "    \n",
    "    # NÃO É PARA USAR HOG, CASCADE OU OUTRAS BLIBLIOTECAS DE DETEÇÃO DE PESSOAS/ROSTOS/OBJETOS\n",
    "    \n",
    "    # Para a deteção e classificação de partes do corpo temos que:\n",
    "    # extrair o corpo humano do fundo (usando o código acima como base)\n",
    "    # encontrar o centroide do corpo\n",
    "    # 2 OPÇÕES:\n",
    "        # ver a cor de pele e ver a parte em que essa cor está mais a esquerda/direita do centroide\n",
    "        # ou a partir dos contornos ver o ponto mais à esquerda/direita do centroide (melhor)\n",
    "        \n",
    "    # Com essa informação podemos fazer a agua a voar para o braço OU fazemos uma mini versão de ti aparecer na tua mão\n",
    "    \n",
    "    # Para cada frame do vídeo cortado entre ini e fin:\n",
    "        # Detectar a pessoa no frame\n",
    "            # Extrair a região do braço\n",
    "            # Pôr a aguia/pessoa no braco/mao detetado(a)\n",
    "    \n",
    "    # Salvar o vídeo processado como video1.mp4\n",
    "    \n",
    "    # Retorna uma String com o nome do arquivo de vídeo processado\n",
    "    return \"video1.avi\"\n",
    "\n",
    "video0 = \"./video0.avi\"\n",
    "ini = 0 # Frame inicial\n",
    "fin = 10 # Frame final\n",
    "video1 = AugmentedReality(video0 ,ini, fin)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
